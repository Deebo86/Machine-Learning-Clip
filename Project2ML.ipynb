{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2L_TERSdCK7I"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from PIL import Image\n",
        "import clip\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PzPdS27o7oOs",
        "outputId": "337a41ae-a586-4378-f00c-7d05d1e8acb1"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('cat_dog1.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ePu26VYm71p1"
      },
      "outputs": [],
      "source": [
        "#a-Spliting the dataset into training and testing sets with 20% for test dataset\n",
        "#made it 0.9 for ease of testing for now\n",
        "train_data, test_data = train_test_split(data, test_size=0.9, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Vgj6n4DuVZ1i",
        "outputId": "9b44a9aa-56ed-42d0-b149-1d119e75e369"
      },
      "outputs": [],
      "source": [
        "# Load the CLIP model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model, transform = clip.load(\"ViT-B/32\", 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mhe841EWchL7"
      },
      "outputs": [],
      "source": [
        "preprocessed_train = []\n",
        "preprocessed_test = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "dS7GtDfhdKMc",
        "outputId": "65693909-bc93-4689-b863-a86550ff03ee"
      },
      "outputs": [],
      "source": [
        "for file in train_data['image']:\n",
        "  preprocessed_train.append(transform(Image.open('cat_dog1/' + file )).unsqueeze(0).to(device))\n",
        "\n",
        "for file in test_data['image']:\n",
        "  preprocessed_test.append(transform(Image.open('cat_dog1/' + file)).unsqueeze(0).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbgBhCWDeQue"
      },
      "outputs": [],
      "source": [
        "#input_img = torch.tensor(np.stack(preprocessed_train)).cpu()\n",
        "#i don't think leeha lazma but i'm leaving it here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "Re1I9nu0eveV",
        "outputId": "9db5712d-0344-4634-f089-363e30f94791"
      },
      "outputs": [],
      "source": [
        "#encode the inputs\n",
        "image_embeddings_train = []\n",
        "image_embeddings_test = []\n",
        "for image in preprocessed_train:\n",
        "  image_embeddings_train.append(model.encode_image(image))\n",
        "\n",
        "for image in preprocessed_test:\n",
        "  image_embeddings_test.append(model.encode_image(image))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dqOKtluBWgVy"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[ 1.0217872e-01,  2.8104293e-01,  1.0210094e-01, ...,\n",
              "          9.5321190e-01,  3.7617832e-02, -1.2722777e-01]],\n",
              "\n",
              "       [[-5.4830801e-01,  9.5876083e-02, -4.1318387e-02, ...,\n",
              "          7.5573874e-01,  8.7017268e-03,  1.3450854e-01]],\n",
              "\n",
              "       [[-2.5290810e-03,  1.0958649e-03, -1.8320274e-01, ...,\n",
              "          1.0545205e+00,  2.4233526e-01,  2.7901149e-01]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-2.8213200e-01,  6.0453430e-02, -1.1066309e-01, ...,\n",
              "          1.1216140e+00,  2.4346091e-02,  3.8230765e-01]],\n",
              "\n",
              "       [[-2.2695100e-01, -1.9104697e-01,  1.3683960e-01, ...,\n",
              "          1.0613921e+00, -1.4923377e-01,  1.2921879e-01]],\n",
              "\n",
              "       [[-1.2724274e-01,  1.0999836e-01,  1.4642596e-01, ...,\n",
              "          1.0680327e+00,  1.6129503e-01,  3.9924258e-01]]], dtype=float32)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_embeddings_train = np.array(image_embeddings_train)\n",
        "image_embeddings_test = np.array(image_embeddings_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Py3GFf7PYZSB"
      },
      "outputs": [],
      "source": [
        "def get_feature_matrix(dataset):\n",
        "    embeddings = [get_clip_embedding(image_path) for image_path in dataset['image_path']]\n",
        "    feature_matrix = torch.stack(embeddings).detach().cpu().numpy()\n",
        "    return feature_matrix\n",
        "\n",
        "# Apply the function to both training and testing datasets\n",
        "train_feature_matrix = get_feature_matrix(train_data)\n",
        "test_feature_matrix = get_feature_matrix(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "IoIw8t0KUclK"
      },
      "outputs": [
        {
          "ename": "LinAlgError",
          "evalue": "0-dimensional array given. Array must be at least two-dimensional",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m means \u001b[38;5;241m=\u001b[39m [image_embeddings_train[train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m label]\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m      4\u001b[0m S \u001b[38;5;241m=\u001b[39m  np\u001b[38;5;241m.\u001b[39mvar(image_embeddings_train[train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mvar(image_embeddings_train[train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m----> 5\u001b[0m S_inv \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m mean_dif \u001b[38;5;241m=\u001b[39m means[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m means[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m w \u001b[38;5;241m=\u001b[39m c\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mdot(S_inv, mean_dif)\n",
            "File \u001b[1;32mc:\\Users\\El-Wattaneya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\linalg\\linalg.py:555\u001b[0m, in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;124;03mCompute the (multiplicative) inverse of a matrix.\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    552\u001b[0m \n\u001b[0;32m    553\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    554\u001b[0m a, wrap \u001b[38;5;241m=\u001b[39m _makearray(a)\n\u001b[1;32m--> 555\u001b[0m \u001b[43m_assert_stacked_2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    556\u001b[0m _assert_stacked_square(a)\n\u001b[0;32m    557\u001b[0m t, result_t \u001b[38;5;241m=\u001b[39m _commonType(a)\n",
            "File \u001b[1;32mc:\\Users\\El-Wattaneya\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\linalg\\linalg.py:206\u001b[0m, in \u001b[0;36m_assert_stacked_2d\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays:\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 206\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-dimensional array given. Array must be \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    207\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat least two-dimensional\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m a\u001b[38;5;241m.\u001b[39mndim)\n",
            "\u001b[1;31mLinAlgError\u001b[0m: 0-dimensional array given. Array must be at least two-dimensional"
          ]
        }
      ],
      "source": [
        "#Fisher's Algorithm\n",
        "c = 0.1\n",
        "means = [image_embeddings_train[train_data['labels'] == label].mean(axis=0) for label in [0, 1]]\n",
        "S =  np.var(image_embeddings_train[train_data['labels'] == 0]) + np.var(image_embeddings_train[train_data['labels'] == 1])\n",
        "S_inv = np.linalg.inv(S)\n",
        "mean_dif = means[1] - means[0]\n",
        "w = c*np.dot(S_inv, mean_dif)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DanOCOOSNzXY"
      },
      "outputs": [],
      "source": [
        "#predictions with c = 0.1\n",
        "predict_c = np.dot(image_embeddings_test, w.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmEwLr23OJA1"
      },
      "outputs": [],
      "source": [
        "#Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dw47Wg4uHJH"
      },
      "outputs": [],
      "source": [
        "#Bonus\n",
        "\n",
        "C = [0.2, 0.3, 0.4, 0.5, 0.7]\n",
        "W = []\n",
        "for c in C:\n",
        "  W.append(c*np.dot(S_inv, mean_dif))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uldlZXd88iYr"
      },
      "outputs": [],
      "source": [
        "predict_C = []\n",
        "for w in W:\n",
        "  predict_C.append(np.dot(image_embeddings_test, w.T))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fqa-wwvkOKsV"
      },
      "outputs": [],
      "source": [
        "#Scores\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
